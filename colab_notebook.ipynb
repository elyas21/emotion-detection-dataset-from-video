{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DTNzpHTjhh1K"
      },
      "source": [
        "# Mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4J_STkMvejm",
        "outputId": "c39ff8fe-bf05-401c-f812-474f36d1fa69"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XlWQV5xxVlzw"
      },
      "outputs": [],
      "source": [
        "# !ls /gdrive/MyDrive/\n",
        "# !mkdir /gdrive/MyDrive/emotionImage\n",
        "# %cp /content/data/rowImg/* /gdrive/MyDrive/emotionImage\n",
        "!mkdir /content/data\n",
        "!mkdir /content/data/rowVid\n",
        "%cp  -r /gdrive/MyDrive/DataEngineering/* /content/data/rowVid"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jD3Q2MMe21tG"
      },
      "source": [
        "\n",
        "\n",
        "# Load and prepare dataset\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JCLBz8WKhdQM"
      },
      "source": [
        "## Load video "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFrxvrpOwGCV",
        "outputId": "b8d19246-8862-4198-e016-99d3f0073f95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFP7Kw2rynpy",
        "outputId": "dfb3ae70-a06d-430d-d177-68ed12590921"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install opencv-contrib-python\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IvReNYQ40vYK"
      },
      "source": [
        "Create dirctories"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4h8KDmoA0YgZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DEcV7s4_yGZM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import shutil , os\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "import os\n",
        "trial, count = 10, 0\n",
        "def gen_img(skipFrame):\n",
        "  if os.path.exists('data/rowImg'):\n",
        "    shutil.rmtree('data/rowImg')\n",
        "  if os.path.exists('data/processed'):\n",
        "    shutil.rmtree('data/processed')\n",
        "  dirs = [\n",
        "      'data',\n",
        "      'data/rowVid',\n",
        "      'data/classification',\n",
        "      'data/rowImg',\n",
        "      'data/processed',\n",
        "      'data/processed/train',\n",
        "      'data/processed/valid',\n",
        "      'data/processed/test',\n",
        "      'data/processed/train/labels',\n",
        "      'data/processed/valid/labels',\n",
        "      'data/processed/test/labels',\n",
        "      'data/processed/train/images',\n",
        "      'data/processed/valid/images',\n",
        "      'data/processed/test/images']\n",
        "\n",
        "  [os.makedirs(p) if not os.path.exists(p) else ''  for p in dirs]\n",
        "\n",
        "\n",
        "  for video in os.listdir('data/rowVid'):\n",
        "    # if trial>count:\n",
        "      if video.endswith('mp4') or video.endswith('avi'):\n",
        "        cap = cv.VideoCapture('/content/data/rowVid/'+video)\n",
        "        # capture.set(cv2.CAP_PROP_POS_FRAMES, 100)\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, 100)\n",
        "\n",
        "\n",
        "        c=1\n",
        "        success,image = cap.read()\n",
        "        count = 0\n",
        "\n",
        "      while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if ret:\n",
        "          # cv2.imwrite('frame{:d}.jpg'.format(count), frame)\n",
        "          \n",
        "          cv.imwrite(f'/content/data/rowImg/'+ str(count) + '-' + video[:-4] + '.png', frame)\n",
        "          count += skipFrame # i.e. at 30 fps, this advances one second\n",
        "          cap.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
        "        else:\n",
        "          cap.release()\n",
        "          break\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MM1ZDvs8xGBI"
      },
      "outputs": [],
      "source": [
        "%cp -r /gdrive/MyDrive/DataEngineering/* /content/data/rowVid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RfKNfwFQ3NRo"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R6AVigsS3D_E"
      },
      "source": [
        "# Load classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tUAuiBAtQ2iW"
      },
      "outputs": [],
      "source": [
        "%mkdir model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RLGraVDXYpj",
        "outputId": "064734f7-a248-4009-a4be-d5a4b0f6969a"
      },
      "outputs": [],
      "source": [
        "!wget -O model/emotionModel.hdf5 https://github.com/Furkan-Gulsen/face-classification/raw/main/models/emotionModel.hdf5\n",
        "# https://github.com/Furkan-Gulsen/face-classification/blob/main/emotionRecognition.py implementatino code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-Dd490V1X9pf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ULxsYExZSOKn"
      },
      "outputs": [],
      "source": [
        "emotionModelPath = 'model/emotionModel.hdf5'  # fer2013_mini_XCEPTION.110-0.65\n",
        "emotionClassifier = load_model(emotionModelPath, compile=False)\n",
        "emotionTargetSize = emotionClassifier.input_shape[1:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_Q2bTHctSV01"
      },
      "outputs": [],
      "source": [
        "def frame_to_prid(x,y,h,w,img):\n",
        "        try:\n",
        "\n",
        "          grayFrame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "          grayFace = grayFrame[y:y + h, x:x + w]\n",
        "          \n",
        "          grayFace = cv2.resize(grayFace, (emotionTargetSize))\n",
        "      \n",
        "          grayFace = grayFace.astype('float32')\n",
        "          grayFace = grayFace / 255.0\n",
        "          grayFace = (grayFace - 0.5) * 2.0\n",
        "          grayFace = np.expand_dims(grayFace, 0)\n",
        "          grayFace = np.expand_dims(grayFace, -1)\n",
        "          emotion_prediction = emotionClassifier.predict(grayFace)\n",
        "          emotion_probability = np.max(emotion_prediction)\n",
        "          # print(emotion_prediction)\n",
        "          # print(emotion_probability)\n",
        "          emotion_label_arg = np.argmax(emotion_prediction)\n",
        "          return str(emotion_label_arg)\n",
        "        except:\n",
        "          pass\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hetezj_1Tp3P"
      },
      "outputs": [],
      "source": [
        "emotions = {\n",
        "    0: {\n",
        "        \"emotion\": \"Angry\",\n",
        "        \"color\": (193, 69, 42)\n",
        "    },\n",
        "    1: {\n",
        "        \"emotion\": \"Disgust\",\n",
        "        \"color\": (164, 175, 49)\n",
        "    },\n",
        "    2: {\n",
        "        \"emotion\": \"Fear\",\n",
        "        \"color\": (40, 52, 155)\n",
        "    },\n",
        "    3: {\n",
        "        \"emotion\": \"Happy\",\n",
        "        \"color\": (23, 164, 28)\n",
        "    },\n",
        "    4: {\n",
        "        \"emotion\": \"Sad\",\n",
        "        \"color\": (164, 93, 23)\n",
        "    },\n",
        "    5: {\n",
        "        \"emotion\": \"Suprise\",\n",
        "        \"color\": (218, 229, 97)\n",
        "    },\n",
        "    6: {\n",
        "        \"emotion\": \"Neutral\",\n",
        "        \"color\": (108, 72, 200)\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KEZyxpIsUy-y"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tS3pX3_IIYlY"
      },
      "source": [
        "# Extract Faces from rowImage using mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EM_l6PxqVr-s",
        "outputId": "c70bff62-1422-415c-908c-0ec6f29ba9a6"
      },
      "outputs": [],
      "source": [
        "!pip install pybboxes mtcnn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dTEVfvb4IfVU"
      },
      "outputs": [],
      "source": [
        "from mtcnn import MTCNN\n",
        "import cv2\n",
        "from pybboxes import BoundingBox\n",
        "import os\n",
        "import pybboxes as pbx\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MRXPlu1s3b9l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "PyZ0q-rLK3ID"
      },
      "outputs": [],
      "source": [
        "# def generate_lable(rowImgDir,(train,val,test),(trainDir,valDir,testDir)):\n",
        "import random ,math\n",
        "import shutil\n",
        "\n",
        "def generate_lable(rowImgDir, tvt, tvt_dir):\n",
        "  shuffled_lst = [x for x in os.listdir(rowImgDir) if os.path.exists(rowImgDir+x) and (x.endswith('.png') or x.endswith('.jpg'))]\n",
        "  random.shuffle(shuffled_lst)\n",
        "  listLen = len(os.listdir(rowImgDir))\n",
        "  train_list = shuffled_lst[0 : math.floor(tvt[0]*listLen)]\n",
        "  valid_list = shuffled_lst[math.floor(tvt[0]*listLen) : math.floor(tvt[1]*listLen)+math.floor(tvt[0]*listLen)]\n",
        "  test_list = shuffled_lst[math.floor(math.floor(tvt[1]*listLen)+math.floor(tvt[0]*listLen)) :-1 ]\n",
        "  dataLists = [train_list, valid_list, test_list]\n",
        "\n",
        "  for i ,lis in enumerate(tqdm(dataLists)):  \n",
        "\n",
        "    for il, fn in enumerate(lis):      \n",
        "      if os.path.exists(rowImgDir+fn) and (fn.endswith('.png') or fn.endswith('.jpg')):\n",
        "        img = cv2.cvtColor(cv2.imread(rowImgDir+fn), cv2.COLOR_BGR2RGB)\n",
        "        detector = MTCNN()\n",
        "\n",
        "        if os.path.exists(tvt_dir[i]+fn[:-4]+'.txt'+'.txt'):\n",
        "          os.remove(tvt_dir[i]+fn[:-4]+'.txt'+'.txt')\n",
        "        for face in detector.detect_faces(img):\n",
        "          try:\n",
        "            \n",
        "              a = face['box']\n",
        "              coco_bbox = BoundingBox.from_coco(*a)\n",
        "              coco_bbox.image_size = (img.shape[1], img.shape[0])\n",
        "              yolo_bbox = coco_bbox.to_yolo()\n",
        "\n",
        "              #get prid\n",
        "              prid = frame_to_prid(a[0], a[1], a[2], a[3], img) \n",
        "\n",
        "              shutil.copyfile(rowImgDir+fn, tvt_dir[i]+'images/'+fn)\n",
        "             \n",
        "              # save yolo bbox\n",
        "              f = open(tvt_dir[i]+'labels/' +fn[:-4]+'.txt', \"a\")\n",
        "              f.write(f''+ prid +' '+ str(yolo_bbox.values[0]) + ' '+ str(yolo_bbox.values[1]) + ' '+ str(yolo_bbox.values[2]) + ' '+ str(yolo_bbox.values[3]) + '\\n')\n",
        "              f.close()\n",
        "              # copy to all\n",
        "          except  Exception as e:\n",
        "            print(e)\n",
        "            continue\n",
        "          # save croped faces to new folder new file\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQSIU4HMR-u6",
        "outputId": "aa18e2b3-8c86-4f35-9c2b-dcc420d50084"
      },
      "outputs": [],
      "source": [
        "# def generate_lable(rowImgDir,(train,val,test),(trainDir,valDir,testDir)):\n",
        "gen_img(600)\n",
        "generate_lable('/content/data/rowImg/', (.4, .3, .3), ('data/processed/train/', 'data/processed/valid/', 'data/processed/test/'))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ttlpLdM2hUtV"
      },
      "source": [
        "# Train Yolo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5oHVEzlUiMKR"
      },
      "source": [
        "[link text](https://)## Extract frames(images from video)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ayOf3fzWZymy"
      },
      "source": [
        "/content/tomato-disease-ofise-16/data.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIkjXR2rZtGJ",
        "outputId": "4e124c7c-1c92-4231-bba4-adba06d46694"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.11 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 23.4/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "from ultralytics import YOLO\n",
        "\n",
        "from IPython.display import display, Image\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7hxzgjvtZzKG"
      },
      "source": [
        "%cd \n",
        "\n",
        "!yolo task=detect mode=train model=yolov8s.pt data={dataset.location}/data.yaml epochs=25 imgsz=800 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy1hXANGh1Mg",
        "outputId": "f1c9ae03-eb82-4a08-d745-13b08c1c9750"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=train model=yolov8s.pt data=\"/content/data.yaml\" epochs=50 imgsz=1000 plots=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPSnIYHfjcJj",
        "outputId": "81651ae2-12f5-47b4-814a-18d158e5f1ce"
      },
      "outputs": [],
      "source": [
        "!yolo task=detect mode=predict model=/content/runs/detect/train7/weights/best.pt conf=0.25 source=/content/data/processed/test/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vPaXzO86vN8c"
      },
      "outputs": [],
      "source": [
        "# for imgName in os.listdir('/content/runs/detect/predict')[0:5]:\n",
        "# Image(filename='/content/runs/detect/predict6/2050-carpoolKaraoke.png', height=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cglQlZgNHEur"
      },
      "outputs": [],
      "source": [
        "# %cp -r /content/data/processed/test/images/* /gdrive/MyDrive/ml/emotionImg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lJX701MiuoKu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
